{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b550efd4-46af-445e-a446-bd6f80b7f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d25d209-ddf9-48cc-b830-a40b70e934ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 378918 × 374\n",
      "    obs: 'fov', 'center_x', 'center_y', 'min_x', 'max_x', 'min_y', 'max_y', 'age', 'clust_annot', 'slice', 'sex_ontology_term_id', 'suspension_type', 'cell_type_ontology_term_id', 'assay_ontology_term_id', 'tissue_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'development_stage_ontology_term_id', 'donor_id', 'is_primary_data', 'cell_type_annot', 'tissue_type', 'cell_type', 'assay', 'disease', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'organism', 'organism_ontology_term_id', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_pca', 'X_spatial_coords', 'X_umap', 'spatial_coords'\n"
     ]
    }
   ],
   "source": [
    "file = \"BrainAgingSpatialAtlas_MERFISH.h5ad\"\n",
    "\n",
    "adata = sc.read_h5ad(file)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aec1777-941b-42ab-a05e-d2277a3737bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_genes=5)\n",
    "sc.pp.filter_genes(adata, min_cells=5)\n",
    "\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, n_comps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae662dd1-cae5-4025-abff-fd6cc3bf86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: torch.Size([378918, 50])\n",
      "Domains: 43\n"
     ]
    }
   ],
   "source": [
    "# ========== Node features ==========\n",
    "X_pca = adata.obsm['X_pca']             # (N_cells, 50 PCs)\n",
    "X = torch.tensor(X_pca, dtype=torch.float)\n",
    "\n",
    "# ========== Spatial coordinates ==========\n",
    "if 'X_spatial_coords' in adata.obsm_keys():\n",
    "    coords = adata.obsm['X_spatial_coords']\n",
    "elif 'spatial_coords' in adata.obsm_keys():\n",
    "    coords = adata.obsm['spatial_coords']\n",
    "else:\n",
    "    coords = adata.obs[['center_x', 'center_y']].to_numpy()\n",
    "\n",
    "coords = coords.astype(float)\n",
    "\n",
    "# ========== Domain labels ==========\n",
    "domains = adata.obs['clust_annot'].astype('category')\n",
    "domain_idx = domains.cat.codes.to_numpy()      # integer labels\n",
    "n_domains = len(domains.cat.categories)\n",
    "\n",
    "print(\"Nodes:\", X.shape)\n",
    "print(\"Domains:\", n_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2354b969-17ae-4f17-bf60-8ca172c0f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial edges: 3470060\n"
     ]
    }
   ],
   "source": [
    "# ----- Build spatial kNN graph -----\n",
    "k = 8\n",
    "n_cells = coords.shape[0]\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree')\n",
    "nbrs.fit(coords)\n",
    "distances, indices = nbrs.kneighbors(coords)\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "weights = []\n",
    "\n",
    "for i in range(n_cells):\n",
    "    for j, d in zip(indices[i, 1:], distances[i, 1:]):\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        weights.append(np.exp(-d))\n",
    "\n",
    "# Build sparse adjacency in COO format\n",
    "A_spatial = sp.coo_matrix((weights, (rows, cols)), shape=(n_cells, n_cells))\n",
    "\n",
    "# Symmetrize adjacency (may convert format internally)\n",
    "A_spatial = A_spatial.maximum(A_spatial.T)\n",
    "\n",
    "# ⭐ Convert back to COO explicitly (fix your error here!)\n",
    "A_spatial = A_spatial.tocoo()\n",
    "\n",
    "# Now you can safely access row, col\n",
    "edge_index = np.vstack([A_spatial.row, A_spatial.col])\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "edge_attr = torch.tensor(A_spatial.data, dtype=torch.float)\n",
    "\n",
    "print(\"Spatial edges:\", edge_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c2906f-6acb-4247-912d-3d6966e99616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDG edges: 483\n",
      "Data(x=[378918, 50], edge_index=[2, 3470060], edge_attr=[3470060], y_domain=[378918], n_domains=43, DD_edge_index=[2, 483], DD_edge_attr=[483])\n"
     ]
    }
   ],
   "source": [
    "# Map domain names to numeric indices\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains.cat.categories)}\n",
    "domain_per_cell = domain_idx\n",
    "\n",
    "# Initialize domain adjacency counts\n",
    "DD_counts = np.zeros((n_domains, n_domains), dtype=float)\n",
    "\n",
    "rows = A_spatial.row\n",
    "cols = A_spatial.col\n",
    "\n",
    "for i_cell, j_cell in zip(rows, cols):\n",
    "    d_i = domain_per_cell[i_cell]\n",
    "    d_j = domain_per_cell[j_cell]\n",
    "    DD_counts[d_i, d_j] += 1\n",
    "    DD_counts[d_j, d_i] += 1\n",
    "\n",
    "eps = 1e-8\n",
    "DD_phys = DD_counts / (DD_counts.sum(axis=1, keepdims=True) + eps)\n",
    "\n",
    "# Compute domain mean vectors in PCA space\n",
    "domain_mean = np.zeros((n_domains, X_pca.shape[1]))\n",
    "domain_counts = np.zeros(n_domains)\n",
    "\n",
    "for cell, d in enumerate(domain_per_cell):\n",
    "    domain_mean[d] += X_pca[cell]\n",
    "    domain_counts[d] += 1\n",
    "\n",
    "domain_counts[domain_counts == 0] = 1\n",
    "domain_mean = domain_mean / domain_counts[:, None]\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "DD_sem = np.zeros((n_domains, n_domains))\n",
    "\n",
    "for i in range(n_domains):\n",
    "    for j in range(n_domains):\n",
    "        vi, vj = domain_mean[i], domain_mean[j]\n",
    "        DD_sem[i, j] = np.dot(vi, vj) / (norm(vi)*norm(vj) + eps)\n",
    "\n",
    "alpha = 0.5   # weight between physical and semantic\n",
    "DD_combined = alpha * DD_phys + (1 - alpha) * DD_sem\n",
    "\n",
    "# threshold weak edges\n",
    "thr = 0.1\n",
    "DD_mask = (DD_combined > thr).astype(float)\n",
    "DD_final = DD_combined * DD_mask\n",
    "\n",
    "DD_rows, DD_cols = np.where(DD_final > 0)\n",
    "DD_weights = DD_final[DD_rows, DD_cols]\n",
    "\n",
    "DD_edge_index = torch.tensor(np.vstack([DD_rows, DD_cols]), dtype=torch.long)\n",
    "DD_edge_attr  = torch.tensor(DD_weights, dtype=torch.float)\n",
    "\n",
    "print(\"DDG edges:\", DD_edge_index.shape[1])\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(\n",
    "    x=X,                        # PCA features\n",
    "    edge_index=edge_index,      # spatial graph edges\n",
    "    edge_attr=edge_attr         # spatial edge weights\n",
    ")\n",
    "\n",
    "# Add domain info + DDG\n",
    "data.y_domain = torch.tensor(domain_per_cell, dtype=torch.long)\n",
    "data.n_domains = n_domains\n",
    "data.DD_edge_index = DD_edge_index\n",
    "data.DD_edge_attr  = DD_edge_attr\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbe8a75-fce5-4367-8f17-347c2e831e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv  # you can switch to GCNConv or GATConv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================\n",
    "# 1. Encoder: MLP + GNN → μ, logσ\n",
    "# ============================\n",
    "\n",
    "class DRASIEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_mlp=128, hidden_gnn=128, latent_dim=32):\n",
    "        super().__init__()\n",
    "        # MLP to compress input features (PCA) before GNN\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_mlp),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_mlp, hidden_gnn),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # GNN layers over spatial graph\n",
    "        self.gnn1 = GraphConv(hidden_gnn, hidden_gnn)\n",
    "        self.gnn2 = GraphConv(hidden_gnn, hidden_gnn)\n",
    "\n",
    "        # Heads for VAE parameters\n",
    "        self.mu_head     = nn.Linear(hidden_gnn, latent_dim)\n",
    "        self.logvar_head = nn.Linear(hidden_gnn, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: (N, in_dim), edge_index: (2, E)\n",
    "        h = self.mlp(x)\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        mu     = self.mu_head(h)\n",
    "        logvar = self.logvar_head(h)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 2. Reparameterization\n",
    "# =======================\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 3. Decoder: z → x̂\n",
    "# =======================\n",
    "\n",
    "class DRASIDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dec=128, out_dim=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dec),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dec, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 4. Full DRA-SI Model\n",
    "# =======================\n",
    "\n",
    "class DRASIModel(nn.Module):\n",
    "    def __init__(self, in_dim, n_domains, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.encoder = DRASIEncoder(in_dim, latent_dim=latent_dim)\n",
    "        self.decoder = DRASIDecoder(latent_dim, out_dim=in_dim)\n",
    "        self.n_domains = n_domains\n",
    "\n",
    "    def forward(self, data):\n",
    "        # data.x, data.edge_index\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        mu, logvar = self.encoder(x, edge_index)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        return x_recon, mu, logvar, z\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 5. Loss components: Recon + KL + DDG\n",
    "# ======================================\n",
    "\n",
    "def loss_recon(x, x_recon):\n",
    "    # MSE between reconstructed and original PCA features\n",
    "    return F.mse_loss(x_recon, x)\n",
    "\n",
    "def loss_kl(mu, logvar):\n",
    "    # KL divergence between q(z|x) and N(0, I)\n",
    "    return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "def compute_domain_means(z, domain_idx, n_domains):\n",
    "    \"\"\"\n",
    "    z: (N, latent_dim)\n",
    "    domain_idx: (N,) int\n",
    "    Returns: (n_domains, latent_dim) mean embeddings.\n",
    "    \"\"\"\n",
    "    latent_dim = z.size(1)\n",
    "    device = z.device\n",
    "\n",
    "    sums = torch.zeros(n_domains, latent_dim, device=device)\n",
    "    counts = torch.zeros(n_domains, device=device)\n",
    "\n",
    "    # accumulate sums & counts\n",
    "    sums.index_add_(0, domain_idx, z)\n",
    "    ones = torch.ones_like(domain_idx, dtype=torch.float, device=device)\n",
    "    counts.index_add_(0, domain_idx, ones)\n",
    "\n",
    "    counts = counts.clamp(min=1.0)\n",
    "    means = sums / counts.unsqueeze(1)\n",
    "    return means\n",
    "\n",
    "def loss_ddg(z, domain_idx, DD_edge_index, DD_edge_attr, n_domains, lambda_ddg=1.0):\n",
    "    \"\"\"\n",
    "    z: (N, latent_dim)\n",
    "    domain_idx: (N,) int\n",
    "    DD_edge_index: (2, E_D)\n",
    "    DD_edge_attr: (E_D,)\n",
    "    \"\"\"\n",
    "    device = z.device\n",
    "    DD_edge_index = DD_edge_index.to(device)\n",
    "    DD_edge_attr  = DD_edge_attr.to(device)\n",
    "    domain_idx    = domain_idx.to(device)\n",
    "\n",
    "    domain_means = compute_domain_means(z, domain_idx, n_domains)  # (D, latent_dim)\n",
    "\n",
    "    d_i = DD_edge_index[0]  # (E_D,)\n",
    "    d_j = DD_edge_index[1]\n",
    "\n",
    "    mu_i = domain_means[d_i]   # (E_D, latent_dim)\n",
    "    mu_j = domain_means[d_j]\n",
    "\n",
    "    diff = mu_i - mu_j\n",
    "    dist_sq = (diff * diff).sum(dim=1)   # (E_D,)\n",
    "\n",
    "    weighted = DD_edge_attr * dist_sq\n",
    "    return lambda_ddg * weighted.mean()\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 6. Total loss wrapper\n",
    "# ======================\n",
    "\n",
    "def total_loss(data, model, lambda_kl=1e-3, lambda_ddg=0.1):\n",
    "    \"\"\"\n",
    "    data: PyG Data\n",
    "    model: DRASIModel\n",
    "    \"\"\"\n",
    "    x = data.x\n",
    "    y_domain = data.y_domain\n",
    "    DD_edge_index = data.DD_edge_index\n",
    "    DD_edge_attr  = data.DD_edge_attr\n",
    "    n_domains = data.n_domains\n",
    "\n",
    "    x_recon, mu, logvar, z = model(data)\n",
    "\n",
    "    L_rec = loss_recon(x, x_recon)\n",
    "    L_kl  = loss_kl(mu, logvar)\n",
    "    L_DDG = loss_ddg(z, y_domain, DD_edge_index, DD_edge_attr, n_domains)\n",
    "\n",
    "    L = L_rec + lambda_kl * L_kl + L_DDG\n",
    "    logs = {\n",
    "        \"loss\": L.item(),\n",
    "        \"rec\": L_rec.item(),\n",
    "        \"kl\": L_kl.item(),\n",
    "        \"ddg\": L_DDG.item()\n",
    "    }\n",
    "    return L, logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dddadc-1146-4066-b14c-f0b9c0b9f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | loss=2.8592 | rec=2.7212 | kl=3.3570 | ddg=0.1346\n",
      "Epoch 010 | loss=2.2824 | rec=2.2697 | kl=0.3398 | ddg=0.0123\n",
      "Epoch 020 | loss=2.2579 | rec=2.2506 | kl=0.9907 | ddg=0.0063\n",
      "Epoch 030 | loss=2.2357 | rec=2.2245 | kl=2.0832 | ddg=0.0091\n",
      "Epoch 040 | loss=2.1967 | rec=2.1788 | kl=3.6401 | ddg=0.0143\n",
      "Epoch 050 | loss=2.1106 | rec=2.0906 | kl=4.6898 | ddg=0.0153\n",
      "Epoch 060 | loss=2.0061 | rec=1.9806 | kl=5.2722 | ddg=0.0202\n",
      "Epoch 070 | loss=1.9298 | rec=1.9014 | kl=4.1097 | ddg=0.0243\n",
      "Epoch 080 | loss=1.8682 | rec=1.8374 | kl=4.3752 | ddg=0.0264\n",
      "Epoch 090 | loss=1.8465 | rec=1.8107 | kl=4.0641 | ddg=0.0317\n",
      "Epoch 100 | loss=1.7925 | rec=1.7509 | kl=4.2492 | ddg=0.0374\n",
      "Latent embedding shape: (378918, 32)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "in_dim = data.x.size(1)\n",
    "n_domains = int(data.n_domains)\n",
    "\n",
    "model = DRASIModel(in_dim=in_dim, n_domains=n_domains, latent_dim=32).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100  # you can increase to 200–300 once things work\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    L, logs = total_loss(data, model, lambda_kl=1e-3, lambda_ddg=0.1)\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"loss={logs['loss']:.4f} | \"\n",
    "            f\"rec={logs['rec']:.4f} | \"\n",
    "            f\"kl={logs['kl']:.4f} | \"\n",
    "            f\"ddg={logs['ddg']:.4f}\"\n",
    "        )\n",
    "\n",
    "# After training, get latent embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, _, _, z = model(data)   # z: (N_cells, latent_dim)\n",
    "\n",
    "z_cpu = z.cpu().numpy()\n",
    "print(\"Latent embedding shape:\", z_cpu.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af7ce59-9e64-4237-bd2c-cd23a7dac43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378918, 32)\n"
     ]
    }
   ],
   "source": [
    "adata.obsm['X_drasi'] = z_cpu\n",
    "print(adata.obsm['X_drasi'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969aa157-c657-4c24-bf8d-0c7c12614b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bASW: 0.98426855\n"
     ]
    }
   ],
   "source": [
    "import scib_metrics\n",
    "\n",
    "from scib_metrics import silhouette_batch  # ✅ top-level, not from .benchmark\n",
    "\n",
    "X = adata.obsm[\"X_drasi\"]                     # (n_cells, n_features)\n",
    "labels = adata.obs[\"cell_type\"].to_numpy()    # or whatever your cell-type column is\n",
    "batch = adata.obs[\"slice\"].to_numpy()         # your batch key\n",
    "\n",
    "bASW = silhouette_batch(\n",
    "    X=X,\n",
    "    labels=labels,\n",
    "    batch=batch,\n",
    "    rescale=True,               # keep [0,1], higher is better\n",
    "    metric=\"euclidean\",\n",
    "    between_cluster_distances=\"nearest\",  # standard ASW, not BRAS\n",
    ")\n",
    "\n",
    "print(\"bASW:\", bASW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2134189-2a83-4321-9c27-caf744e3cdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
